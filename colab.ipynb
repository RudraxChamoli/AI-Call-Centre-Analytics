{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: assemblyai in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: httpx>=0.19.0 in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from assemblyai) (0.27.2)\n",
      "Requirement already satisfied: pydantic!=1.10.7,>=1.7.0 in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from assemblyai) (2.10.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7 in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from assemblyai) (4.12.2)\n",
      "Requirement already satisfied: websockets>=11.0 in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from assemblyai) (14.1)\n",
      "Requirement already satisfied: anyio in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from httpx>=0.19.0->assemblyai) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from httpx>=0.19.0->assemblyai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from httpx>=0.19.0->assemblyai) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from httpx>=0.19.0->assemblyai) (3.10)\n",
      "Requirement already satisfied: sniffio in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from httpx>=0.19.0->assemblyai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from httpcore==1.*->httpx>=0.19.0->assemblyai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from pydantic!=1.10.7,>=1.7.0->assemblyai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\code\\emotion youtube\\lemur-call-analysis-app\\aaienv\\lib\\site-packages (from pydantic!=1.10.7,>=1.7.0->assemblyai) (2.27.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install assemblyai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the transcript with sentiment scores\n",
    "# and determines the overall sentiment of the call.\n",
    "\n",
    "# def analyze_sentiment(transcript):\n",
    "#   all_sentiment_scores = [(sentiment.sentiment) for sentiment in transcript.sentiment_analysis]\n",
    "#   sentiments_count = {\"POSITIVE\": all_sentiment_scores.count(\"POSITIVE\"), \"NEGATIVE\": all_sentiment_scores.count(\"NEGATIVE\")}\n",
    "\n",
    "#   if sentiments_count[\"POSITIVE\"] > sentiments_count[\"NEGATIVE\"]:\n",
    "#     return \"POSITIVE\"\n",
    "#   elif sentiments_count[\"POSITIVE\"] < sentiments_count[\"NEGATIVE\"]:\n",
    "#     return \"NEGATIVE\"\n",
    "#   else:\n",
    "#     return \"NEUTRAL\"\n",
    "  \n",
    "def analyze_sentiment(transcript):\n",
    "    if not transcript or not hasattr(transcript, 'sentiment_analysis') or not transcript.sentiment_analysis:\n",
    "        raise ValueError(\"Sentiment analysis data is missing from the transcript.\")\n",
    "\n",
    "    all_sentiment_scores = [sentiment.sentiment for sentiment in transcript.sentiment_analysis]\n",
    "    sentiments_count = {\n",
    "        \"POSITIVE\": all_sentiment_scores.count(\"POSITIVE\"),\n",
    "        \"NEGATIVE\": all_sentiment_scores.count(\"NEGATIVE\"),\n",
    "    }\n",
    "\n",
    "    if sentiments_count[\"POSITIVE\"] > sentiments_count[\"NEGATIVE\"]:\n",
    "        return \"POSITIVE\"\n",
    "    elif sentiments_count[\"NEGATIVE\"] > sentiments_count[\"POSITIVE\"]:\n",
    "        return \"NEGATIVE\"\n",
    "    else:\n",
    "        return \"NEUTRAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function extracts action items from the audio file\n",
    "# using AssemblyAI's LeMUR framework.\n",
    "\n",
    "def get_action_items(transcript):\n",
    "  result = transcript.lemur.action_items(\n",
    "      context = \"This is a transcript of a call between a customer and a call center agent.\",\n",
    "      answer_format=\"**<topic header>**\\n<relevant action items>\\n\",\n",
    "  )\n",
    "\n",
    "  return result.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the file path of an audio file\n",
    "# and sends it for transcription and sentiment analysis.\n",
    "\n",
    "def send_to_api(file_path):\n",
    "  aai.settings.api_key = \"96d951d54c7f4fdcbf60618df6fbab15\"\n",
    "\n",
    "  transcriber = aai.Transcriber()\n",
    "\n",
    "  try:\n",
    "      transcript = transcriber.transcribe(file_path, aai.TranscriptionConfig(sentiment_analysis=True))\n",
    "  except Exception as e:\n",
    "      print(f\"Trancription error: {e}\")\n",
    "      return None\n",
    "\n",
    "  sentiment = analyze_sentiment(transcript)\n",
    "\n",
    "  try:\n",
    "      action_items = get_action_items(transcript)\n",
    "  except aai.types.LemurError as e:\n",
    "      print(f\"Lemur error: {e}\")\n",
    "      action_items= \"Error extracting action items.\"\n",
    "      return None\n",
    "  return {\n",
    "      \"sentiment\": sentiment,\n",
    "      \"action_items\" : action_items.split('\\n')\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sentiment analysis data is missing from the transcript.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m jsonObject \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_api\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNegative-call.m4a\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m, in \u001b[0;36msend_to_api\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrancription error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranscript\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     action_items \u001b[38;5;241m=\u001b[39m get_action_items(transcript)\n",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[1;34m(transcript)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_sentiment\u001b[39m(transcript):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transcript \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transcript, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transcript\u001b[38;5;241m.\u001b[39msentiment_analysis:\n\u001b[1;32m---> 17\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiment analysis data is missing from the transcript.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m     all_sentiment_scores \u001b[38;5;241m=\u001b[39m [sentiment\u001b[38;5;241m.\u001b[39msentiment \u001b[38;5;28;01mfor\u001b[39;00m sentiment \u001b[38;5;129;01min\u001b[39;00m transcript\u001b[38;5;241m.\u001b[39msentiment_analysis]\n\u001b[0;32m     20\u001b[0m     sentiments_count \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSITIVE\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_sentiment_scores\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSITIVE\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEGATIVE\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_sentiment_scores\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEGATIVE\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     23\u001b[0m     }\n",
      "\u001b[1;31mValueError\u001b[0m: Sentiment analysis data is missing from the transcript."
     ]
    }
   ],
   "source": [
    "jsonObject = send_to_api('Negative-call.m4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "print(textwrap.fill(str(jsonObject), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
